{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
       "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Info        35816\n",
       "never          35095\n",
       "former          9352\n",
       "current         9286\n",
       "not current     6447\n",
       "ever            4004\n",
       "Name: smoking_history, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smoking_history'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    58552\n",
       "Male      41430\n",
       "Other        18\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.885856</td>\n",
       "      <td>0.07485</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>27.320767</td>\n",
       "      <td>5.527507</td>\n",
       "      <td>138.058060</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.516840</td>\n",
       "      <td>0.26315</td>\n",
       "      <td>0.194593</td>\n",
       "      <td>6.636783</td>\n",
       "      <td>1.070672</td>\n",
       "      <td>40.708136</td>\n",
       "      <td>0.278883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.630000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.580000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.690000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  hypertension  heart_disease            bmi  \\\n",
       "count  100000.000000  100000.00000  100000.000000  100000.000000   \n",
       "mean       41.885856       0.07485       0.039420      27.320767   \n",
       "std        22.516840       0.26315       0.194593       6.636783   \n",
       "min         0.080000       0.00000       0.000000      10.010000   \n",
       "25%        24.000000       0.00000       0.000000      23.630000   \n",
       "50%        43.000000       0.00000       0.000000      27.320000   \n",
       "75%        60.000000       0.00000       0.000000      29.580000   \n",
       "max        80.000000       1.00000       1.000000      95.690000   \n",
       "\n",
       "         HbA1c_level  blood_glucose_level       diabetes  \n",
       "count  100000.000000        100000.000000  100000.000000  \n",
       "mean        5.527507           138.058060       0.085000  \n",
       "std         1.070672            40.708136       0.278883  \n",
       "min         3.500000            80.000000       0.000000  \n",
       "25%         4.800000           100.000000       0.000000  \n",
       "50%         5.800000           140.000000       0.000000  \n",
       "75%         6.200000           159.000000       0.000000  \n",
       "max         9.000000           300.000000       1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96146, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    87664\n",
       "1     8482\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17877   415]\n",
      " [  451  1257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     18292\n",
      "           1       0.75      0.74      0.74      1708\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.86      0.86      0.86     20000\n",
      "weighted avg       0.96      0.96      0.96     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest classifier on the resampled dataset\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18103   189]\n",
      " [  487  1221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18292\n",
      "           1       0.87      0.71      0.78      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.92      0.85      0.88     20000\n",
      "weighted avg       0.96      0.97      0.96     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['diabetes_model.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "\n",
    "one_hot_columns = X.columns\n",
    "joblib.dump(one_hot_columns, 'one_hot_columns.pkl')\n",
    "\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest classifier on the resampled dataset\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf, 'diabetes_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level',\n",
       "       'blood_glucose_level', 'gender_Female', 'gender_Male', 'gender_Other',\n",
       "       'smoking_history_No Info', 'smoking_history_current',\n",
       "       'smoking_history_ever', 'smoking_history_former',\n",
       "       'smoking_history_never', 'smoking_history_not current'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            0\n",
       "hypertension                   0\n",
       "heart_disease                  0\n",
       "bmi                            0\n",
       "HbA1c_level                    0\n",
       "blood_glucose_level            0\n",
       "diabetes                       0\n",
       "gender_Female                  0\n",
       "gender_Male                    0\n",
       "gender_Other                   0\n",
       "smoking_history_No Info        0\n",
       "smoking_history_current        0\n",
       "smoking_history_ever           0\n",
       "smoking_history_former         0\n",
       "smoking_history_never          0\n",
       "smoking_history_not current    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            float64\n",
       "hypertension                     int64\n",
       "heart_disease                    int64\n",
       "bmi                            float64\n",
       "HbA1c_level                    float64\n",
       "blood_glucose_level              int64\n",
       "diabetes                         int64\n",
       "gender_Female                    uint8\n",
       "gender_Male                      uint8\n",
       "gender_Other                     uint8\n",
       "smoking_history_No Info          uint8\n",
       "smoking_history_current          uint8\n",
       "smoking_history_ever             uint8\n",
       "smoking_history_former           uint8\n",
       "smoking_history_never            uint8\n",
       "smoking_history_not current      uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16229  2063]\n",
      " [  269  1439]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93     18292\n",
      "           1       0.41      0.84      0.55      1708\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.70      0.86      0.74     20000\n",
      "weighted avg       0.93      0.88      0.90     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Assuming the dataframe is already loaded in 'df'\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Logistic Regression model on the resampled dataset\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17562   730]\n",
      " [  464  1244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     18292\n",
      "           1       0.63      0.73      0.68      1708\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.80      0.84      0.82     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Logistic Regression model on the resampled dataset\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18218    74]\n",
      " [  508  1200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.94      0.70      0.80      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.96      0.85      0.89     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train an XGBoost model on the resampled dataset\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17447    62]\n",
      " [  522  1199]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17509\n",
      "           1       0.95      0.70      0.80      1721\n",
      "\n",
      "    accuracy                           0.97     19230\n",
      "   macro avg       0.96      0.85      0.89     19230\n",
      "weighted avg       0.97      0.97      0.97     19230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df = df.drop_duplicates()\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train an XGBoost model on the resampled dataset\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 73208, number of negative: 73208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 146416, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[[18240    52]\n",
      " [  520  1188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.96      0.70      0.81      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.97      0.85      0.90     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a LightGBM model on the resampled dataset\n",
    "lgb_clf = LGBMClassifier(objective='binary', random_state=42)\n",
    "lgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 73208, number of negative: 73208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 146416, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Confusion Matrix:\n",
      "[[18228    64]\n",
      " [  520  1188]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.95      0.70      0.80      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.96      0.85      0.89     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n",
      "Instance 1:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9883\n",
      "Probability of Class 1: 0.0117\n",
      "\n",
      "Instance 2:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 1.0000\n",
      "Probability of Class 1: 0.0000\n",
      "\n",
      "Instance 3:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9999\n",
      "Probability of Class 1: 0.0001\n",
      "\n",
      "Instance 4:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9976\n",
      "Probability of Class 1: 0.0024\n",
      "\n",
      "Instance 5:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.8973\n",
      "Probability of Class 1: 0.1027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Save the column names for future use\n",
    "one_hot_columns = X.columns\n",
    "joblib.dump(one_hot_columns, 'one_hot_columns.pkl')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Train a LightGBM model on the resampled dataset\n",
    "lgb_clf = LGBMClassifier(objective='binary', random_state=42)\n",
    "lgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(lgb_clf, 'diabetes_model.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_proba = lgb_clf.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Show some predicted probabilities for the first 5 test instances\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"Predicted Class: {y_pred[i]}\")\n",
    "    print(f\"Probability of Class 0: {y_pred_proba[i][0]:.4f}\")\n",
    "    print(f\"Probability of Class 1: {y_pred_proba[i][1]:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
       "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  hypertension  heart_disease  bmi  HbA1c_level  blood_glucose_level  \\\n",
      "0   25             0              0   28          5.8                  188   \n",
      "\n",
      "   gender_Female  gender_Male  gender_Other  smoking_history_No Info  \\\n",
      "0              1            0             0                        0   \n",
      "\n",
      "   smoking_history_current  smoking_history_ever  smoking_history_former  \\\n",
      "0                        0                     0                       0   \n",
      "\n",
      "   smoking_history_never  smoking_history_not current  \n",
      "0                      1                            0  \n",
      "Predicted Class: 0\n",
      "Probability of Class 1: 0.0126\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the model, scaler, and column orders\n",
    "model = joblib.load('diabetes_model.joblib')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "one_hot_columns = joblib.load('one_hot_columns.pkl')\n",
    "\n",
    "# Example new data (ensure it matches the training data structure)\n",
    "new_data = pd.DataFrame([{\n",
    "    'gender': 'Female',\n",
    "    'age': 25,\n",
    "    'hypertension': 0,\n",
    "    'heart_disease': 0,\n",
    "    'smoking_history': 'never',\n",
    "    'bmi': 28,\n",
    "    'HbA1c_level': 5.8,\n",
    "    'blood_glucose_level': 188\n",
    "}])\n",
    "\n",
    "# One-hot encode new data\n",
    "new_data_encoded = pd.get_dummies(new_data, columns=['gender', 'smoking_history'])\n",
    "new_data_encoded = new_data_encoded.reindex(columns=one_hot_columns, fill_value=0)\n",
    "print(new_data_encoded)\n",
    "# Scale new data\n",
    "new_data_scaled = scaler.transform(new_data_encoded)\n",
    "\n",
    "# Make predictions\n",
    "prediction = model.predict(new_data_scaled)[0]\n",
    "probability = model.predict_proba(new_data_scaled)[0][1]\n",
    "\n",
    "print(f\"Predicted Class: {prediction}\")\n",
    "print(f\"Probability of Class 1: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 73208, number of negative: 73208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 146416, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Confusion Matrix:\n",
      "[[18240    52]\n",
      " [  520  1188]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.96      0.70      0.81      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.97      0.85      0.90     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n",
      "Instance 1:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9910\n",
      "Probability of Class 1: 0.0090\n",
      "\n",
      "Instance 2:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9999\n",
      "Probability of Class 1: 0.0001\n",
      "\n",
      "Instance 3:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9999\n",
      "Probability of Class 1: 0.0001\n",
      "\n",
      "Instance 4:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9981\n",
      "Probability of Class 1: 0.0019\n",
      "\n",
      "Instance 5:\n",
      "Predicted Class: 0\n",
      "Probability of Class 0: 0.9020\n",
      "Probability of Class 1: 0.0980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "# df = df.drop_duplicates()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a LightGBM model on the resampled dataset\n",
    "lgb_clf = LGBMClassifier(objective='binary', random_state=42)\n",
    "lgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_proba = lgb_clf.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Show some predicted probabilities for the first 5 test instances\n",
    "for i in range(5):\n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"Predicted Class: {y_pred[i]}\")\n",
    "    print(f\"Probability of Class 0: {y_pred_proba[i][0]:.4f}\")\n",
    "    print(f\"Probability of Class 1: {y_pred_proba[i][1]:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 70155, number of negative: 70155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 140310, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[[17479    30]\n",
      " [  532  1189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17509\n",
      "           1       0.98      0.69      0.81      1721\n",
      "\n",
      "    accuracy                           0.97     19230\n",
      "   macro avg       0.97      0.84      0.90     19230\n",
      "weighted avg       0.97      0.97      0.97     19230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df = df.drop_duplicates()\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a LightGBM model on the resampled dataset\n",
    "lgb_clf = LGBMClassifier(objective='binary', random_state=42)\n",
    "lgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 73208, number of negative: 73208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 808\n",
      "[LightGBM] [Info] Number of data points in the train set: 146416, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[[18156   136]\n",
      " [  488  1220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18292\n",
      "           1       0.90      0.71      0.80      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.94      0.85      0.89     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a LightGBM model on the resampled dataset\n",
    "lgb_clf = LGBMClassifier(objective='binary', random_state=42)\n",
    "lgb_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26684\\2035519205.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Apply SMOTE to the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Train a CatBoost model on the resampled dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1012\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_features = ['gender', 'smoking_history']\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a CatBoost model on the resampled dataset\n",
    "cat_model = CatBoostClassifier(cat_features=categorical_features)\n",
    "cat_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16460  1832]\n",
      " [  384  1324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94     18292\n",
      "           1       0.42      0.78      0.54      1708\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.70      0.84      0.74     20000\n",
      "weighted avg       0.93      0.89      0.90     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Assuming the dataframe is already loaded in 'df'\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a k-NN model on the resampled dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16517  1775]\n",
      " [  369  1339]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94     18292\n",
      "           1       0.43      0.78      0.56      1708\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.70      0.84      0.75     20000\n",
      "weighted avg       0.93      0.89      0.91     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "# Assuming the dataframe is already loaded in 'df'\n",
    "# label_encoder = LabelEncoder()\n",
    "# df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "# df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a k-NN model on the resampled dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17737   555]\n",
      " [  434  1274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     18292\n",
      "           1       0.70      0.75      0.72      1708\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.84      0.86      0.85     20000\n",
      "weighted avg       0.95      0.95      0.95     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Use get_dummies for one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['gender', 'smoking_history'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Decision Tree classifier on the resampled dataset\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17692   600]\n",
      " [  437  1271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     18292\n",
      "           1       0.68      0.74      0.71      1708\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.83      0.86      0.84     20000\n",
      "weighted avg       0.95      0.95      0.95     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Assuming the dataframe is already loaded in 'df'\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop('diabetes', axis=1)  # assuming 'diabetes' is the target variable\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Decision Tree classifier on the resampled dataset\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 83s 10ms/step - loss: 0.1102 - accuracy: 0.9624\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 108s 14ms/step - loss: 0.0883 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 122s 15ms/step - loss: 0.0853 - accuracy: 0.9706\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 75s 9ms/step - loss: 0.0844 - accuracy: 0.9707\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 47s 6ms/step - loss: 0.0838 - accuracy: 0.9713\n",
      "625/625 [==============================] - 11s 12ms/step\n",
      "Accuracy: 97.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=10, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the model\n",
    "model.save('diabetes_model.h5')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18238    54]\n",
      " [  537  1171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18292\n",
      "           1       0.96      0.69      0.80      1708\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.96      0.84      0.89     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14642/14642 [==============================] - 101s 7ms/step - loss: 0.2063 - accuracy: 0.9015\n",
      "Epoch 2/5\n",
      "14642/14642 [==============================] - 94s 6ms/step - loss: 0.1784 - accuracy: 0.9126\n",
      "Epoch 3/5\n",
      "14642/14642 [==============================] - 94s 6ms/step - loss: 0.1751 - accuracy: 0.9145\n",
      "Epoch 4/5\n",
      "14642/14642 [==============================] - 92s 6ms/step - loss: 0.1730 - accuracy: 0.9150\n",
      "Epoch 5/5\n",
      "14642/14642 [==============================] - 81s 6ms/step - loss: 0.1690 - accuracy: 0.9177\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Accuracy: 91.14%\n",
      "[[16739  1553]\n",
      " [  219  1489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     18292\n",
      "           1       0.49      0.87      0.63      1708\n",
      "\n",
      "    accuracy                           0.91     20000\n",
      "   macro avg       0.74      0.89      0.79     20000\n",
      "weighted avg       0.94      0.91      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "\n",
    "df= pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_resampled, epochs=5, batch_size=10, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Save the model\n",
    "# model.save('diabetes_model.h5')\n",
    "\n",
    "# # Save the scaler\n",
    "# joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
